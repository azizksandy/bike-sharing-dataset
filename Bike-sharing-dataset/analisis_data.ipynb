{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":36778,"sourceType":"datasetVersion","datasetId":28865}],"dockerImageVersionId":3200,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Importing libraries","metadata":{"_uuid":"6e22e6f0d6b15ed5ac7656134d375f10515708a2"}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn import metrics\nfrom sklearn import preprocessing\nfrom sklearn import linear_model\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_predict\nfrom sklearn.model_selection import cross_val_score","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":"## Importing data\n","metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"}},{"cell_type":"code","source":"hour_df = pd.read_csv(\"../input/bike-sharing-dataset/hour.csv\")\nhour_df.info()","metadata":{"_uuid":"fd03c90918cb0018143c69825fbce90cf989d96c","trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"markdown","source":"## Preprocessing","metadata":{"_uuid":"58b4d42dae2d41eee51752fbe1361dd72cfac69e"}},{"cell_type":"code","source":"# Renaming columns names to more readable names\nhour_df.rename(columns={'instant':'rec_id',\n                        'dteday':'datetime',\n                        'holiday':'is_holiday',\n                        'workingday':'is_workingday',\n                        'weathersit':'weather_condition',\n                        'hum':'humidity',\n                        'mnth':'month',\n                        'cnt':'total_count',\n                        'hr':'hour',\n                        'yr':'year'},inplace=True)\n\n###########################\n# Setting proper data types\n###########################\n# date time conversion\nhour_df['datetime'] = pd.to_datetime(hour_df.datetime)\n\n# categorical variables\nhour_df['season'] = hour_df.season.astype('category')\nhour_df['is_holiday'] = hour_df.is_holiday.astype('category')\nhour_df['weekday'] = hour_df.weekday.astype('category')\nhour_df['weather_condition'] = hour_df.weather_condition.astype('category')\nhour_df['is_workingday'] = hour_df.is_workingday.astype('category')\nhour_df['month'] = hour_df.month.astype('category')\nhour_df['year'] = hour_df.year.astype('category')\nhour_df['hour'] = hour_df.hour.astype('category')","metadata":{"_uuid":"39883b04c2e2a2d7e3f441b7c683cfeaedeeefa2","collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"markdown","source":"## Plotting","metadata":{"_uuid":"b27adc5d6a7a82b941537d3a31d91e7b502effb7"}},{"cell_type":"code","source":"# Configuring plotting visual and sizes\nsns.set_style('whitegrid')\nsns.set_context('talk')\nparams = {'legend.fontsize': 'x-large',\n          'figure.figsize': (30, 10),\n          'axes.labelsize': 'x-large',\n          'axes.titlesize':'x-large',\n          'xtick.labelsize':'x-large',\n          'ytick.labelsize':'x-large'}\n\nplt.rcParams.update(params)","metadata":{"_uuid":"0114a01f2dd06211592eacfc6d2662a6b8ee6f74","collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"fig,ax = plt.subplots()\nsns.pointplot(data=hour_df[['hour',\n                           'total_count',\n                           'season']],\n              x='hour',\n              y='total_count',\n              hue='season',\n              ax=ax)\nax.set(title=\"Season wise hourly distribution of counts\")","metadata":{"_uuid":"151daf8e51e4ac86322d825626ad5f6e537d47e8","trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"fig,ax = plt.subplots()\nsns.pointplot(data=hour_df[['hour',\n                           'total_count',\n                           'weekday']],\n              x='hour',\n              y='total_count',\n              hue='weekday',\n              ax=ax)\nax.set(title=\"Weekday wise hourly distribution of counts\")","metadata":{"_uuid":"ebfe780fcac15e296ec8d0892ed0e73a78f52303","trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"fig,ax = plt.subplots()\nsns.barplot(data=hour_df[['month',\n                           'total_count']],\n              x='month',\n              y='total_count',\n              ax=ax)\nax.set(title=\"Monthly distribution of counts\")","metadata":{"_uuid":"e4d86264aba8c5c86ead8712740a41a68df600e0","trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"fig,ax = plt.subplots()\nsns.barplot(data=hour_df[['season',\n                           'total_count']],\n              x='season',\n              y='total_count',\n              ax=ax)\nax.set(title=\"Seasonal distribution of counts\")","metadata":{"_uuid":"28d818628fbbd7b3a6e39ea3ab8059b04b0f8561","trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"fig,ax = plt.subplots()\nsns.violinplot(data=hour_df[['year',\n                           'total_count']],\n              x='year',\n              y='total_count',\n              ax=ax)\nax.set(title=\"Year distribution of counts\")","metadata":{"_uuid":"8e2ad675fa0ad05a81c4efb6c90f745956ec2868","trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"markdown","source":"#### Checking for outliners:","metadata":{"_uuid":"afd9009d8a981d1781c4298ef4444560f859bfbd"}},{"cell_type":"code","source":"fig,(ax1,ax2) = plt.subplots(ncols=2)\nsns.boxplot(data=hour_df[['total_count',\n                          'casual',\n                          'registered']],ax=ax1)\nsns.boxplot(data=hour_df[['temp',\n                          'windspeed']],ax=ax2)","metadata":{"_uuid":"0ca7aa3437f8723ece78f80e922684f9dde66709","trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"fig,ax = plt.subplots()\nsns.boxplot(data=hour_df[['total_count',\n                          'hour']],x='hour',y='total_count',ax=ax)\nax.set(title=\"Checking for outliners in day hours\")","metadata":{"_uuid":"86219e0ead23b0e5aa35e116e2915139bacc3558","trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"markdown","source":"#### Correlations","metadata":{"_uuid":"f9cea8179da932b8936a1943b3a2106ea8b495a1","trusted":true}},{"cell_type":"code","source":"corrMatt = hour_df[['temp',\n                    'atemp', \n                    'humidity', \n                    'windspeed', \n                    'casual', \n                    'registered', \n                    'total_count']].corr()\n\nmask = np.array(corrMatt)\n# Turning the lower-triangle of the array to false\nmask[np.tril_indices_from(mask)] = False\nfig,ax = plt.subplots()\nsns.heatmap(corrMatt, \n            mask=mask,\n            vmax=.8, \n            square=True,\n            annot=True,\n            ax=ax)","metadata":{"_uuid":"99ca62ae498651f46ff1b621be77898e918ee97b","trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"markdown","source":"## Feature Engineering\nSince the dataset contains multiple categorical variables, it is imperative that we encode the nominal ones before we use them in our modeling process.","metadata":{"_uuid":"0f90f6ca9111a8db9e5a4c99a08262b785da82b8","trusted":true}},{"cell_type":"code","source":"# Defining categorical variables encoder method\ndef fit_transform_ohe(df,col_name):\n    \"\"\"This function performs one hot encoding for the specified\ncolumn.\n    Args:\n        df(pandas.DataFrame): the data frame containing the mentioned column name\n        col_name: the column to be one hot encoded\n    Returns:\n        tuple: label_encoder, one_hot_encoder, transformed column as pandas Series\n    \"\"\"\n    # label encode the column\n    le = preprocessing.LabelEncoder()\n    le_labels = le.fit_transform(df[col_name])\n    df[col_name+'_label'] = le_labels\n    # one hot encoding\n    ohe = preprocessing.OneHotEncoder()\n    feature_arr = ohe.fit_transform(df[[col_name+'_label']]).toarray()\n    feature_labels = [col_name+'_'+str(cls_label) for cls_label in le.classes_]\n    features_df = pd.DataFrame(feature_arr, columns=feature_labels)\n    return le,ohe,features_df\n\n# given label encoder and one hot encoder objects, \n# encode attribute to ohe\ndef transform_ohe(df,le,ohe,col_name):\n    \"\"\"This function performs one hot encoding for the specified\n        column using the specified encoder objects.\n\n    Args:\n        df(pandas.DataFrame): the data frame containing the mentioned column name\n        le(Label Encoder): the label encoder object used to fit label encoding\n        ohe(One Hot Encoder): the onen hot encoder object used to fit one hot encoding\n        col_name: the column to be one hot encoded\n\n    Returns:\n        tuple: transformed column as pandas Series\n\n    \"\"\"\n    # label encode\n    col_labels = le.transform(df[col_name])\n    df[col_name+'_label'] = col_labels\n    \n    # ohe \n    feature_arr = ohe.fit_transform(df[[col_name+'_label']]).toarray()\n    feature_labels = [col_name+'_'+str(cls_label) for cls_label in le.classes_]\n    features_df = pd.DataFrame(feature_arr, columns=feature_labels)\n    \n    return features_df","metadata":{"_uuid":"459e9cb07e630467f34f7168b509bf21883bac37","collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"# Divide the dataset into training and testing sets\nX, X_test, y, y_test = train_test_split(hour_df.iloc[:,0:-3],\n                                        hour_df.iloc[:,-1],\n                                        test_size=0.33,\n                                        random_state=42)\nX.reset_index(inplace=True)\ny = y.reset_index()\n\nX_test.reset_index(inplace=True)\ny_test = y_test.reset_index()","metadata":{"_uuid":"c881d93a061e25613e4ef4c750c5ba22679c30c4","collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"# Encoding all the categorical features\ncat_attr_list = ['season','is_holiday',\n                 'weather_condition','is_workingday',\n                 'hour','weekday','month','year']\n# though we have transformed all categoricals into their one-hot encodings, note that ordinal\n# attributes such as hour, weekday, and so on do not require such encoding.\nnumeric_feature_cols = ['temp','humidity','windspeed',\n                        'hour','weekday','month','year']\nsubset_cat_features =  ['season','is_holiday','weather_condition','is_workingday']\n\n###############\n# Train dataset\n###############\nencoded_attr_list = []\nfor col in cat_attr_list:\n    return_obj = fit_transform_ohe(X,col)\n    encoded_attr_list.append({'label_enc':return_obj[0],\n                              'ohe_enc':return_obj[1],\n                              'feature_df':return_obj[2],\n                              'col_name':col})\n\n\nfeature_df_list  = [X[numeric_feature_cols]]\nfeature_df_list.extend([enc['feature_df'] \\\n                        for enc in encoded_attr_list \\\n                        if enc['col_name'] in subset_cat_features])\n\ntrain_df_new = pd.concat(feature_df_list, axis=1)\nprint(\"Train dataset shape::{}\".format(train_df_new.shape))\nprint(train_df_new.head())\n\n##############\n# Test dataset\n##############\ntest_encoded_attr_list = []\nfor enc in encoded_attr_list:\n    col_name = enc['col_name']\n    le = enc['label_enc']\n    ohe = enc['ohe_enc']\n    test_encoded_attr_list.append({'feature_df':transform_ohe(X_test,\n                                                              le,ohe,\n                                                              col_name),\n                                   'col_name':col_name})\n    \n    \ntest_feature_df_list = [X_test[numeric_feature_cols]]\ntest_feature_df_list.extend([enc['feature_df'] \\\n                             for enc in test_encoded_attr_list \\\n                             if enc['col_name'] in subset_cat_features])\n\ntest_df_new = pd.concat(test_feature_df_list, axis=1) \nprint(\"Test dataset shape::{}\".format(test_df_new.shape))\nprint(test_df_new.head())","metadata":{"_uuid":"f556f4115e1235fe929c2e9cecd37d7d4cfd8eb8","trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"markdown","source":"## Modeling","metadata":{"_uuid":"08822028e19b8394c49283d20757c92d657101f3","trusted":true}},{"cell_type":"code","source":"X = train_df_new\ny = y.total_count.values.reshape(-1,1)\n\nlin_reg = linear_model.LinearRegression()\n\n# using the k-fold cross validation (specifically 10-fold) to reduce overfitting affects\n# cross_val_predict function returns cross validated prediction values as fitted by the model object.\npredicted = cross_val_predict(lin_reg, X, y, cv=10)","metadata":{"_uuid":"347fb4d1f8754a4aedb5906a76d7b093867ee09a","collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"# Analysing residuals in our predictinos\nfig,ax = plt.subplots(figsize=(15,15))\nax.scatter(y, y-predicted)\nax.axhline(lw=2,color='black')\nax.set_xlabel('Observed')\nax.set_ylabel('Residual')\nax.set_title('Residual Plot')\nplt.show()","metadata":{"_uuid":"365cb481d930a502a3a178217a74e226ae968fad","trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"# Evaluating model in cross-validation iteration\n\nr2_scores = cross_val_score(lin_reg, X, y, cv=10)\nmse = cross_val_score(lin_reg, X, y, cv=10,scoring='neg_mean_squared_error')\n\nfig,ax = plt.subplots()\nax.plot(range(0,10),\n        r2_scores)\nax.set_xlabel('Iteration')\nax.set_ylabel('R.Squared')\nax.set_title('Cross-Validation scores')\nplt.show()\n\n\nprint(\"R-squared::{}\".format(r2_scores))\nprint(\"MSE::{}\".format(mse))","metadata":{"_uuid":"e0f259c707cc1fcc4792605686a0172ac8a64ba9","trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"markdown","source":"## Testing dataset evaluation","metadata":{"_uuid":"7f667e45e4ea581ef8127fdc5771ff030d01b57e","trusted":true}},{"cell_type":"code","source":"# Predict model based on training dataset\nlin_reg.fit(X,y)\n\n# Constructing test dataset\nX_test = test_df_new\ny_test = y_test.total_count.values.reshape(-1,1)\n\n\ny_pred = lin_reg.predict(X_test)\nresiduals = y_test-y_pred\n\nfig, ax = plt.subplots(figsize=(15,15))\nax.scatter(y_test, residuals)\nax.axhline(lw=2,color='black')\nax.set_xlabel('Observed')\nax.set_ylabel('Residuals')\nax.title.set_text(\"Residual Plot with R-Squared={}\".format(np.average(lin_reg.score(X_test,y_test))))\nplt.show()\n\nprint(\"MSE: {}\".format(metrics.mean_squared_error(y_test, y_pred)))","metadata":{"_uuid":"85bd6136ba4332f6dcc62612dd9e86057efbf781","trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"markdown","source":"As we can cleary see, the performance is dismal due to non-linearity of independent variables to dependent features and we could only predict around 40 percent of the outcomes.","metadata":{"_uuid":"4ab0ddb88e6e06d30fd403805cd4f56d2c9e3a85","trusted":true}},{"cell_type":"code","source":"","metadata":{"_uuid":"a3c385919e8caa43451cb73b7fda3f781ced7ade","collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]}]}